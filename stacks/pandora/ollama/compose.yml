services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    hostname: ollama
    restart: unless-stopped
    networks:
      - ollama
    # ports:
    #   - 11434:11434/tcp
    environment:
      - OLLAMA_KEEP_ALIVE=5m
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      - TZ=${TZ}
    volumes:
      - /mnt/user/appdata/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  ollama-ui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-ui
    hostname: ollama-ui
    restart: unless-stopped
    depends_on:
      - ollama
    networks:
      - proxy
      - ollama
    # ports:
    #   - 8080:8080/tcp # web ui
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_URL=https://chat.${DOMAIN}
      - TZ=${TZ}
    volumes:
      - /mnt/user/appdata/ollama-ui:/app/backend/data
    labels:
      - traefik.enable=true
      - traefik.http.routers.ollama-ui.entrypoints=http
      - traefik.http.routers.ollama-ui.rule=Host(`chat.${DOMAIN}`)
      - traefik.http.routers.ollama-ui.service=ollama-ui
      - traefik.http.services.ollama-ui.loadbalancer.server.port=8080

networks:
  proxy:
    external: true
  ollama:
    name: ollama
